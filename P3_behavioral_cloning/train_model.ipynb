{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_paths(df, folder):\n",
    "    #convert paths of datalog to those on local computer\n",
    "    for i in range(len(df)):\n",
    "        for col in ['img_center', 'img_left', 'img_right']:\n",
    "            file = df.ix[i, col].split('/')[-1]\n",
    "            img_path = os.path.join(img_folder, file)\n",
    "            df.ix[i, col] = img_path\n",
    "    return df\n",
    "\n",
    "def load_datasets(folders):\n",
    "    #load datasets from multiple folders\n",
    "    dataframes = []\n",
    "    for folder in folders:\n",
    "        df = pd.read_csv(os.path.join(folder, 'driving_log.csv'))\n",
    "        df.columns = ['img_center', 'img_left', 'img_right', 'steering', 'throttle', 'break', 'speed']\n",
    "        df = convert_paths(df, folder)\n",
    "        dataframes.append(df)\n",
    "    df = pd.concat(dataframes)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/udacity_projects/P3_behavioral_cloning/driving_data/'\n",
    "track1_path = os.path.join(data_path, 'track_1')\n",
    "img_folder = os.path.join(track1_path, 'IMG')\n",
    "\n",
    "folders = [track1_path]\n",
    "df = load_datasets(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_data(row, img_col, \n",
    "             steering_col='steering', steering_adjust=.1):\n",
    "    \n",
    "    img = Image.open(df[img_col][row])\n",
    "    img_arr = np.array(img)\n",
    "    angle = df[steering_col][row] + steering_adjust\n",
    "    return img_arr, angle\n",
    "\n",
    "\n",
    "def data_gen(df, batch_size=32, adjust=.1, sample_ix=None):\n",
    "    arg_choices = [{'img_col': 'img_center', 'adjust': 0.0},\n",
    "                   {'img_col': 'img_left',   'adjust': adjust},\n",
    "                   {'img_col': 'img_right',  'adjust': -adjust},]\n",
    "       \n",
    "    if sample_ix is None:\n",
    "        sample_ix = list(range(len(df)))\n",
    "        random.shuffle(sample_ix)\n",
    "    \n",
    "    #print(df.head())\n",
    "    while True:\n",
    "        images=[]\n",
    "        angles=[]\n",
    "        rows = sample_ix[:batch_size]\n",
    "        for i in rows:\n",
    "            args = random.choice(arg_choices)\n",
    "            img, angle = get_data(i, args['img_col'], steering_adjust=args['adjust'])\n",
    "\n",
    "            \n",
    "            flip = random.randint(0, 1)\n",
    "            if flip == 1:\n",
    "                img = np.fliplr(img)\n",
    "                angle = -angle\n",
    "                \n",
    "            images.append(img)\n",
    "            angles.append(angle)\n",
    "\n",
    "        X_train = np.array(images)\n",
    "        y_train = np.array(angles)\n",
    "        yield X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create index of all data\n",
    "n = len(df)\n",
    "sample_ix = list(range(n))\n",
    "random.shuffle(sample_ix)\n",
    "\n",
    "#separate index into train and validation\n",
    "train_n = round(n * .8)\n",
    "train_ix = sample_ix[:train_n]\n",
    "val_ix = sample_ix[train_n:]\n",
    "\n",
    "#create data generators with those indexes\n",
    "train_gen = data_gen(df, sample_ix=train_ix)\n",
    "val_gen = data_gen(df, sample_ix=val_ix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, merge\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, SimpleRNN, Reshape, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Cropping2D, Lambda\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    '''\n",
    "    Function to create models with convolutional heads and dense tails.\n",
    "    Accepts dictionaries defining the conv and dense layers.\n",
    "    '''\n",
    "\n",
    "    img_in = Input(shape=(160, 320,3), name='img_in')\n",
    "    \n",
    "    x = Cropping2D(cropping=((70, 25), (0, 0)), data_format=None)(img_in)\n",
    "    x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Convolution2D(32, (5,5), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x = Flatten(name='flattened')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    angle = Dense(1, activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle])\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "100/100 [==============================] - 7s - loss: 0.5878 - val_loss: 0.1315\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 7s - loss: 0.1392 - val_loss: 0.1327\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 7s - loss: 0.1405 - val_loss: 0.1340\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 6s - loss: 0.1397 - val_loss: 0.1329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f442e73f048>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_gen, 100, epochs=4, validation_data=val_gen, validation_steps=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
